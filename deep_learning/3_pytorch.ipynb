{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Этот пример сгенерировала нейросеть Gemini от Google. Я его подшаманила, и получилось вот все, что ниже - кода много и он сумбурный. Но с PyTorch это всегда так. Проще, конечно, работать с Keras.\n",
        "\n",
        "Простая сеть - SimpleNet:\n",
        "\n",
        "1. Импорт библиотек: Импортируем необходимые модули PyTorch.\n",
        "2. Определение архитектуры нейросети:\n",
        "* Создаем класс SimpleNet, наследующий от nn.Module.\n",
        "* В конструкторе (__init__) определяем линейный слой (nn.Linear) с одним входом и одним выходом.\n",
        "* Метод forward описывает прямой проход данных через сеть.\n",
        "3. Создание экземпляра нейросети: Создаем объект model класса SimpleNet.\n",
        "4. Определение функции потерь и оптимизатора:\n",
        "* Используем среднеквадратичную ошибку (nn.MSELoss) в качестве функции потерь.\n",
        "* Выбираем стохастический градиентный спуск (torch.optim.SGD) в качестве оптимизатора с шагом обучения 0.01.\n",
        "5. Данные для обучения: Создаем тензоры с обучающими данными (вход x_train и целевые значения y_train).\n",
        "6. Цикл обучения:\n",
        "* В цикле for выполняем итерации обучения.\n",
        "* На каждой итерации:\n",
        " * Вычисляем выходные значения модели (outputs).\n",
        " * Вычисляем значение функции потерь (loss).\n",
        " * Обнуляем градиенты (optimizer.zero_grad()).\n",
        " * Вычисляем градиенты (loss.backward()).\n",
        " * Обновляем веса модели (optimizer.step()).\n",
        " * Выводим значение потерь каждые 100 эпох.\n",
        "* Тестирование нейросети:\n",
        " * Отключаем вычисление градиентов (torch.no_grad()).\n",
        " * Создаем тестовый тензор x_test.\n",
        " * Получаем прогноз модели (predicted).\n",
        " * Выводим результат.\n",
        "\n",
        "Это самый простой пример нейросети на PyTorch, который демонстрирует основные этапы создания, обучения и использования модели."
      ],
      "metadata": {
        "id": "YBR4Biy1KNv3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNjQBT67F9Tl",
        "outputId": "32c96805-de43-4dd5-f582-3b1a0393e4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.2648\n",
            "Epoch [200/1000], Loss: 0.1636\n",
            "Epoch [300/1000], Loss: 0.1011\n",
            "Epoch [400/1000], Loss: 0.0625\n",
            "Epoch [500/1000], Loss: 0.0386\n",
            "Epoch [600/1000], Loss: 0.0239\n",
            "Epoch [700/1000], Loss: 0.0147\n",
            "Epoch [800/1000], Loss: 0.0091\n",
            "Epoch [900/1000], Loss: 0.0056\n",
            "Epoch [1000/1000], Loss: 0.0035\n",
            "Прогноз для 4.0: 7.8820\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Определение архитектуры нейросети\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # Один вход, один выход\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Создание экземпляра нейросети\n",
        "model = SimpleNet()\n",
        "\n",
        "# Определение функции потерь и оптимизатора\n",
        "criterion = nn.MSELoss()  # Среднеквадратичная ошибка\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # Стохастический градиентный спуск\n",
        "\n",
        "# Данные для обучения\n",
        "x_train = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "y_train = torch.tensor([[2.0], [4.0], [6.0]])\n",
        "\n",
        "# Цикл обучения\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    # Прямой проход\n",
        "    outputs = model(x_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Обратный проход и оптимизация\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Тестирование нейросети\n",
        "with torch.no_grad():\n",
        "    x_test = torch.tensor([[4.0]])\n",
        "    predicted = model(x_test)\n",
        "    print(f'Прогноз для 4.0: {predicted.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сеть для определения цифр из датасета MNIST:\n",
        "\n",
        "1. Загрузка данных MNIST: Используем torchvision.datasets.MNIST для загрузки данных. Преобразуем изображения в тензоры и создаем загрузчики данных (DataLoader).\n",
        "2. Архитектура нейросети:\n",
        "* Определяем нейросеть с тремя полносвязными слоями (nn.Linear).\n",
        "* Используем функцию активации ReLU (F.relu) после первых двух слоев.\n",
        "* Выходной слой имеет 10 нейронов (для 10 классов цифр).\n",
        "3. Функция потерь и оптимизатор:\n",
        "* Используем кросс-энтропию (nn.CrossEntropyLoss) в качестве функции потерь для классификации.\n",
        "* Выбираем оптимизатор Adam (torch.optim.Adam).\n",
        "4. Цикл обучения:\n",
        "* Итерируемся по эпохам и батчам обучающих данных.\n",
        "* Выполняем прямой и обратный проход, обновляем веса модели.\n",
        "* Выводим значение потерь каждые 100 батчей.\n",
        "5. Тестирование:\n",
        "* Вычисляем точность (accuracy)."
      ],
      "metadata": {
        "id": "5UryrgG8JssP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Гиперпараметры\n",
        "num_epochs = 5\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# Создание загрузчиков данных\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Определение архитектуры нейросети\n",
        "class SimpleMNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleMNISTNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Входной слой\n",
        "        self.fc2 = nn.Linear(128, 64)  # Скрытый слой\n",
        "        self.fc3 = nn.Linear(64, 10)  # Выходной слой (10 классов)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Преобразование изображения в вектор\n",
        "        x = F.relu(self.fc1(x))  # Функция активации ReLU\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Создание экземпляра нейросети\n",
        "model = SimpleMNISTNet()\n",
        "\n",
        "# Определение функции потерь и оптимизатора\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Цикл обучения\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Прямой проход\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Обратный проход и оптимизация\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Тестирование нейросети\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Точность на тестовых данных: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imMZoiFcI-qP",
        "outputId": "f001046f-defb-4070-ed64-d5ec8ae54094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 19498214.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 640814.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1148366.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5485323.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/938], Loss: 0.4349\n",
            "Epoch [1/5], Step [200/938], Loss: 0.1170\n",
            "Epoch [1/5], Step [300/938], Loss: 0.2140\n",
            "Epoch [1/5], Step [400/938], Loss: 0.3913\n",
            "Epoch [1/5], Step [500/938], Loss: 0.3335\n",
            "Epoch [1/5], Step [600/938], Loss: 0.2594\n",
            "Epoch [1/5], Step [700/938], Loss: 0.1397\n",
            "Epoch [1/5], Step [800/938], Loss: 0.1629\n",
            "Epoch [1/5], Step [900/938], Loss: 0.1911\n",
            "Epoch [2/5], Step [100/938], Loss: 0.2317\n",
            "Epoch [2/5], Step [200/938], Loss: 0.2644\n",
            "Epoch [2/5], Step [300/938], Loss: 0.1276\n",
            "Epoch [2/5], Step [400/938], Loss: 0.1841\n",
            "Epoch [2/5], Step [500/938], Loss: 0.0946\n",
            "Epoch [2/5], Step [600/938], Loss: 0.1818\n",
            "Epoch [2/5], Step [700/938], Loss: 0.1495\n",
            "Epoch [2/5], Step [800/938], Loss: 0.1816\n",
            "Epoch [2/5], Step [900/938], Loss: 0.0966\n",
            "Epoch [3/5], Step [100/938], Loss: 0.0949\n",
            "Epoch [3/5], Step [200/938], Loss: 0.1009\n",
            "Epoch [3/5], Step [300/938], Loss: 0.1723\n",
            "Epoch [3/5], Step [400/938], Loss: 0.1659\n",
            "Epoch [3/5], Step [500/938], Loss: 0.1114\n",
            "Epoch [3/5], Step [600/938], Loss: 0.0850\n",
            "Epoch [3/5], Step [700/938], Loss: 0.1541\n",
            "Epoch [3/5], Step [800/938], Loss: 0.0409\n",
            "Epoch [3/5], Step [900/938], Loss: 0.1019\n",
            "Epoch [4/5], Step [100/938], Loss: 0.0471\n",
            "Epoch [4/5], Step [200/938], Loss: 0.0498\n",
            "Epoch [4/5], Step [300/938], Loss: 0.1309\n",
            "Epoch [4/5], Step [400/938], Loss: 0.0251\n",
            "Epoch [4/5], Step [500/938], Loss: 0.0542\n",
            "Epoch [4/5], Step [600/938], Loss: 0.0369\n",
            "Epoch [4/5], Step [700/938], Loss: 0.0747\n",
            "Epoch [4/5], Step [800/938], Loss: 0.1995\n",
            "Epoch [4/5], Step [900/938], Loss: 0.0434\n",
            "Epoch [5/5], Step [100/938], Loss: 0.1107\n",
            "Epoch [5/5], Step [200/938], Loss: 0.0490\n",
            "Epoch [5/5], Step [300/938], Loss: 0.0108\n",
            "Epoch [5/5], Step [400/938], Loss: 0.0104\n",
            "Epoch [5/5], Step [500/938], Loss: 0.0634\n",
            "Epoch [5/5], Step [600/938], Loss: 0.0050\n",
            "Epoch [5/5], Step [700/938], Loss: 0.0124\n",
            "Epoch [5/5], Step [800/938], Loss: 0.0238\n",
            "Epoch [5/5], Step [900/938], Loss: 0.0389\n",
            "Точность на тестовых данных: 97.39%\n"
          ]
        }
      ]
    }
  ]
}