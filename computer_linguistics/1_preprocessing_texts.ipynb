{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Предобработка текста перед тем, как его анализировать, это важный этап, от которого во многом зависит результат. Здесь приведены некоторые примеры предобработки."
      ],
      "metadata": {
        "id": "7QAHKkj-8X7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Напоминаю, что импорты лучше запускать в отдельной ячейке\n",
        "# в самом начале документа.\n",
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "TceSPJyIf49y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Перевод в нижний регистр может удалить информацию об именах собственных,\n",
        "# о начале предложения, об эмоциональной составляющей (тональности)\n",
        "# сообщения.\n",
        "text = \"\"\"Вера, Надежда, Любовь\n",
        "Один. Два. Три.\n",
        "ФАНТАСТИКА!! СУПЕР!\"\"\"\n",
        "print(text.lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOPpKTX3d4Ky",
        "outputId": "b9bcdfa1-fa1f-4bad-d021-f90cb1ff3585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "вера, надежда, любовь\n",
            "один. два. три.\n",
            "фантастика!! супер!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# При помощи регулярных выражений можно оставить только\n",
        "# алфавитные символы и числа.\n",
        "# Узнать, что делает регулярное выражение, можно вот здесь: https://regex101.com/\n",
        "text = 'Алекса́ндр Серге́евич Пу́шкин (26 мая [6 июня] 1799, Москва — 29 января [10 февраля] 1837, Санкт-Петербург) — русский поэт, драматург и прозаик, заложивший основы русского реалистического направления[2], литературный критик[3] и теоретик литературы, историк[3], публицист, журналист[3], редактор и издатель[4].'\n",
        "text = re.sub(r'[^\\w\\s-]+', '', text)\n",
        "print(text)\n",
        "# Особенностью текстов, скачанных с Википедии, являются ссылки на исчтоник\n",
        "# в квадратных скобках. Можно просто удалить все числа, если они оказались\n",
        "# в конце слова и как бы приклеены к нему. Но тут мы заходим на тонкий лед:\n",
        "# а что если перед нами, например, интересное имя собственное (например, U2\n",
        "# название группы)? И обратите внимание, что мне приходится указать алфавит:\n",
        "# а-яА-Я сработает только для кириллицы.\n",
        "words_with_numbers = re.findall(r'[а-яА-Я]+[0-9]', text)\n",
        "for wwn in words_with_numbers:\n",
        "    clean_word = re.sub(r'[0-9]', '', wwn)\n",
        "    text = re.sub(wwn, clean_word, text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yaXAKYrcm6w",
        "outputId": "b17c0382-eee8-4f64-d394-84a831742b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Александр Сергеевич Пушкин 26 мая 6 июня 1799 Москва  29 января 10 февраля 1837 Санкт-Петербург  русский поэт драматург и прозаик заложивший основы русского реалистического направления2 литературный критик3 и теоретик литературы историк3 публицист журналист3 редактор и издатель4\n",
            "Александр Сергеевич Пушкин 26 мая 6 июня 1799 Москва  29 января 10 февраля 1837 Санкт-Петербург  русский поэт драматург и прозаик заложивший основы русского реалистического направления литературный критик и теоретик литературы историк публицист журналист редактор и издатель\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Интересно, что некоторые символы на самом деле состоят из двух.\n",
        "for char in 'а́':\n",
        "    print(char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c48vy3gkfxZ6",
        "outputId": "6e3902b9-63de-4bb8-d34b-2a5698c28a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "а\n",
            "́\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Лично я рекомендую делать деЁфикацию. Не забудьте про регистр.\n",
        "text = \"Ёж и Ежи Фарыно\"\n",
        "print(re.sub(r'ё', 'е', text.lower()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbaz4Yn_eo-J",
        "outputId": "0e357163-ab7f-4a04-e4d6-e61bbf413cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "еж и ежи фарыно\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтобы удалить стоп-слова, необязательно создавать собственный список.\n",
        "# Такие списки есть в NLP-библиотеках, например spacy и NLTK.\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "rus_stop_words = stopwords.words(\"russian\")\n",
        "print(rus_stop_words)\n",
        "# Можно добавить в этот список свои слова.\n",
        "rus_stop_words.append('сколько')\n",
        "print(rus_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJllKFLLyoXr",
        "outputId": "9f0e547c-6c89-4adf-ea03-e01ea1c99cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n",
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между', 'сколько']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Вечор, ты помнишь, вьюга злилась, На мутном небе мгла носилась\"\n",
        "# Удалим пунктуацию.\n",
        "text = re.sub(r'[^\\w\\s-]+', '', text)\n",
        "# Переведем текст в нижний регистр и поделим на токены (split).\n",
        "split_text = text.lower().split()\n",
        "clean_text = ''\n",
        "for token in split_text:\n",
        "    if token not in rus_stop_words:\n",
        "        clean_text += token+' '\n",
        "print(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twVB5vrW2iJI",
        "outputId": "a5561687-b9fd-41af-ced5-a715ac5f1fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "вечор помнишь вьюга злилась мутном небе мгла носилась \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Лемматизация, то есть превращение слова в начальную форму (\"иду -> идти\"),\n",
        "# это довольно сложный процесс. Но есть более простой способ унифицировать\n",
        "# формы слов в тексте - стемминг. Этот алгоритм отсекает от слова окончания,\n",
        "# а иногда даже суфиксы и префиксы. Сколько отсекает - зависит от алгоритма.\n",
        "# Так что оцените эффект разных стеммеров и выберите тот, который лучше\n",
        "# подходит под вашу задачу.\n",
        "# В NLTK есть только один стеммер для русского языка.\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "snowball_stemmer = SnowballStemmer(\"russian\")"
      ],
      "metadata": {
        "id": "M5OSyyUtzq1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'глокая куздра штеко будланула бокра'\n",
        "print([snowball_stemmer.stem(token) for token in text.split()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFcyqbFt3SOK",
        "outputId": "1fa23bbe-44f4-4aef-ca96-3198611164f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['глок', 'куздр', 'штек', 'будланул', 'бокр']\n"
          ]
        }
      ]
    }
  ]
}